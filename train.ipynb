{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from re import X\n",
    "from xxlimited import Str\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.lr_monitor import LearningRateMonitor\n",
    "from pytorch_lightning.profiler import SimpleProfiler\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mo2cap2 import Mo2Cap2DataModule\n",
    "from dataset.mocap import MocapDataModule\n",
    "from dataset.mo2cap2 import Mo2Cap2DataModule\n",
    "from dataset.mocap_distance import MocapDistanceDataModule\n",
    "from dataset.mocap_h36m_cropped_hm import MocapH36MCropHMDataModule\n",
    "from dataset.mocap_h36m_hm import MocapH36MHMDataModule\n",
    "from dataset.mocap_transformer import MocapSeqDataModule\n",
    "from dataset.mo2cap2_transformer import Mo2Cap2SeqDataModule\n",
    "from dataset.mocap_h36m import MocapH36MDataModule\n",
    "from dataset.mocap_h36m_cropped import MocapH36MCropDataModule\n",
    "from dataset.mocap_h36m_transformer import MocapH36MSeqDataModule\n",
    "from dataset.mocap_h36m_cropped_transformer import MocapH36MCropSeqDataModule\n",
    "from dataset.mocap_h36m_2d import Mocap2DH36MDataModule\n",
    "\n",
    "from net.DirectRegression import DirectRegression\n",
    "from net.HRNetBaseline import HRNetBaseline\n",
    "from net.HRNetEgo import HRNetEgoSTAN\n",
    "from net.Mo2Cap2BaselineL1 import Mo2Cap2BaselineL1\n",
    "from net.Mo2Cap2Direct import Mo2Cap2Direct\n",
    "from net.Mo2Cap2GlobalTrans import Mo2Cap2GlobalTrans\n",
    "from net.Mo2Cap2Seq import Mo2Cap2Seq\n",
    "from net.Mo2Cap2SeqHMDirect import Mo2Cap2SeqHMDirect\n",
    "from net.Mo2Cap2SeqHMDirectAvg import Mo2Cap2SeqHMDirectAvg\n",
    "from net.Mo2Cap2SeqHMDirectSlice import Mo2Cap2SeqHMDirectSlice\n",
    "from net.xRNetBaseLine2D import xREgoPose2D\n",
    "from net.xRNetBaseLineL1 import xREgoPoseL1\n",
    "from net.xRNetDirect import xREgoPoseDirect\n",
    "from net.Mo2Cap2Baseline import Mo2Cap2Baseline\n",
    "from net.xRNetPosterior2D import xREgoPosePosterior2D\n",
    "from net.xRNetPosteriorLinear import xREgoPosePosteriorLinear\n",
    "from net.xRNetSeq import xREgoPoseSeq\n",
    "from net.xRNetBaseLine import xREgoPose\n",
    "from net.xRNetConcat import xRNetConcat\n",
    "from net.xRNetHeatmap import xREgoPoseHeatMap\n",
    "from net.xRNetSeqHM import xREgoPoseSeqHM\n",
    "from net.xRNetPosterior import xREgoPosePosterior\n",
    "from net.xRNetPosteriorDist import xREgoPosePosteriorDist\n",
    "from net.xRNetSeqDirect import xREgoPoseSeqDirect\n",
    "from net.xRNetSeqHMDirect import xREgoPoseSeqHMDirect\n",
    "from net.xRNetGlobalTrans import xREgoPoseGlobalTrans\n",
    "from net.xRNetDist import xREgoPoseDist\n",
    "from net.xRNetSeqHMDirectAvg import xREgoPoseSeqHMDirectAvg\n",
    "from net.xRNetSeqHMDirectED import xREgoPoseSeqHMDirectED\n",
    "from net.xRNetSeqHMDirectEDExp import xREgoPoseSeqHMDirectEDExp\n",
    "from net.xRNetSeqHMDirectRevPos import xREgoPoseSeqHMDirectRevPos\n",
    "from net.xRNetSeqHMDirectSlice import xREgoPoseSeqHMDirectSlice\n",
    "from net.xRNetUNet import xREgoPoseUNet\n",
    "from utils.evaluate import create_results_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_DIRECTORY = {\n",
    "    \"direct_regression\": DirectRegression,\n",
    "    \"xregopose\": xREgoPose,\n",
    "    \"xregopose_l1\": xREgoPoseL1,\n",
    "    \"xregopose_seq\": xREgoPoseSeq,\n",
    "    \"xregopose_concat\":xRNetConcat,\n",
    "    \"xregopose_heatmap\": xREgoPoseHeatMap,\n",
    "    \"xregopose_seq_hm\": xREgoPoseSeqHM,\n",
    "    \"xregopose_posterior\": xREgoPosePosterior,\n",
    "    \"xregopose_posterior_2d\": xREgoPosePosterior2D,\n",
    "    \"xregopose_posterior_dist\": xREgoPosePosteriorDist,\n",
    "    \"xregopose_posterior_linear\": xREgoPosePosteriorLinear,\n",
    "    \"xregopose_seq_hm_direct\": xREgoPoseSeqHMDirect,\n",
    "    \"xregopose_seq_hm_direct_ed\": xREgoPoseSeqHMDirectED,\n",
    "    \"xregopose_seq_hm_direct_ed_exp\": xREgoPoseSeqHMDirectEDExp,\n",
    "    \"xregopose_seq_direct\": xREgoPoseSeqDirect,\n",
    "    \"xregopose_global_trans\": xREgoPoseGlobalTrans,\n",
    "    \"xregopose_dist\": xREgoPoseDist,\n",
    "    \"xregopose_unet\": xREgoPoseUNet,\n",
    "    \"xregopose_direct\": xREgoPoseDirect,\n",
    "    \"xregopose_seq_hm_direct_rev_pos\": xREgoPoseSeqHMDirectRevPos,\n",
    "    \"xregopose_seq_hm_direct_avg\": xREgoPoseSeqHMDirectAvg,\n",
    "    \"xregopose_seq_hm_direct_slice\": xREgoPoseSeqHMDirectSlice,\n",
    "    \"mo2cap2\": Mo2Cap2Baseline,\n",
    "    \"mo2cap2_l1\": Mo2Cap2BaselineL1,\n",
    "    \"mo2cap2_direct\": Mo2Cap2Direct,\n",
    "    \"mo2cap2_global_trans\": Mo2Cap2GlobalTrans,\n",
    "    \"mo2cap2_seq\": Mo2Cap2Seq,\n",
    "    \"mo2cap2_slice\": Mo2Cap2SeqHMDirectSlice,\n",
    "    \"mo2cap2_avg\": Mo2Cap2SeqHMDirectAvg,\n",
    "    \"mo2cap2_ego\": Mo2Cap2SeqHMDirect,\n",
    "    \"xregopose_2d\": xREgoPose2D,\n",
    "    \"HRNetBaseline\": HRNetBaseline,\n",
    "    \"HRNetEgoSTAN\": HRNetEgoSTAN\n",
    "\n",
    "\n",
    "}\n",
    "DATALOADER_DIRECTORY = {\n",
    "    'baseline': MocapDataModule,\n",
    "    'sequential': MocapSeqDataModule,\n",
    "    'distance': MocapDistanceDataModule,\n",
    "    'mo2cap2': Mo2Cap2DataModule,\n",
    "    'mo2cap2_seq': Mo2Cap2SeqDataModule,\n",
    "    'h36m_static': MocapH36MDataModule,\n",
    "    'h36m_seq' : MocapH36MSeqDataModule,\n",
    "    'h36m_2d' : Mocap2DH36MDataModule,\n",
    "    'h36m_hm': MocapH36MHMDataModule,\n",
    "    'h36m_crop': MocapH36MCropDataModule,\n",
    "    'h36m_crop_hm': MocapH36MCropHMDataModule,\n",
    "    'h36m_seq_crop': MocapH36MCropSeqDataModule,\n",
    "} \n",
    "\n",
    "# ann_file_val = r'F:\\extracted_mo2cap2_dataset\\TestSet'\n",
    "# ann_file_train = r'F:\\extracted_mo2cap2_dataset\\TrainSet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_args = {\n",
    "\t'model': 'mo2cap2_l1',\n",
    "\t'eval': False,\n",
    "\t'dataloader': 'mo2cap2',\n",
    "\t'load': None,\n",
    "\t'resume_from_checkpoint': None,\n",
    "\t# 'dataset_tr': r'F:\\extracted_mo2cap2_dataset\\TrainSet',\n",
    "\t'dataset_tr': r'F:\\mo2cap2_data_half\\TrainSet',\n",
    "\t'dataset_val': r'F:\\mo2cap2_data_small\\TrainSet',\n",
    "\t'dataset_test': r'F:\\extracted_mo2cap2_dataset\\TestSet',\n",
    "\t'cuda': 'cuda',\n",
    "\t'gpus': 1,\n",
    "\t'batch_size': 48,\n",
    "\t'epoch': 10,\n",
    "\t'num_workers': 4,\n",
    "\t'val_freq': 0.1,\n",
    "\t'es_patience': 5,\n",
    "\t'logdir': r'C:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\temp_res',\n",
    "\t'lr': 0.001,\n",
    "\t'load_resnet': r'C:\\Users\\user\\.cache\\torch\\hub\\checkpoints\\resnet101-63fe2227.pth',\n",
    "\t# 'hm_train_steps': 100000,\n",
    "\t'hm_train_steps': 10000,\n",
    "\t'seq_len': 5,\n",
    "\t'skip': 0,\n",
    "\t'encoder_type': 'branch_concat',\n",
    "\t'heatmap_type': 'baseline',\n",
    "\t'heatmap_resolution': [47, 47],\n",
    "\t'image_resolution': [368, 368],\n",
    "\t'seed': 42,\n",
    "\t'clip_grad_norm': 0.0,\n",
    "\t'dropout': 0.0,\n",
    "\t'dropout_linear': 0.0,\n",
    "\t'protocol': 'p2',\n",
    "\t'w2c': False,\n",
    "\t'weight_regularization': 0.01,\n",
    "\t'monitor_metric': 'val_mpjpe_full_body',\n",
    "\t'sigma': 3,\n",
    "\t'h36m_sample_rate': 1,\n",
    "\t'csv_mode': '3D'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\net\\Mo2Cap2BaselineL1.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.heatmap.resnet101.load_state_dict(torch.load(self.load_resnet))\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(dict_args['seed'])\n",
    "# Initialize model to train\n",
    "assert dict_args['model'] in MODEL_DIRECTORY\n",
    "if dict_args['load'] is not None:\n",
    "\tmodel = MODEL_DIRECTORY[dict_args['model']].load_from_checkpoint(dict_args['load'], **dict_args)\n",
    "else:\n",
    "\tmodel = MODEL_DIRECTORY[dict_args['model']](**dict_args)\n",
    "\n",
    "# Initialize logging paths\n",
    "random_sec = random.randint(1, 20)\n",
    "time.sleep(random_sec)\n",
    "now = datetime.datetime.now().strftime('%m%d%H%M%S')\n",
    "weight_save_dir = os.path.join(dict_args[\"logdir\"], os.path.join('models', 'state_dict', now))\n",
    "while os.path.exists(weight_save_dir):\n",
    "\trandom_sec = random.randint(1, 20)\n",
    "\ttime.sleep(random_sec)\n",
    "\tnow = datetime.datetime.now().strftime('%m%d%H%M%S')\n",
    "\tweight_save_dir = os.path.join(dict_args[\"logdir\"], os.path.join('models', 'state_dict', now))\n",
    "\n",
    "os.makedirs(weight_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Callback: early stopping parameters\n",
    "early_stopping_callback = EarlyStopping(\n",
    "\tmonitor=dict_args['monitor_metric'],\n",
    "\tmode=\"min\",\n",
    "\tverbose=True,\n",
    "\tpatience=dict_args[\"es_patience\"],\n",
    ")\n",
    "\n",
    "# Callback: model checkpoint strategy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "\tdirpath=weight_save_dir, save_top_k=5, verbose=True, monitor=dict_args['monitor_metric'], mode=\"min\"\n",
    ")\n",
    "\n",
    "# Data: load data module\n",
    "assert dict_args['dataloader'] in DATALOADER_DIRECTORY\n",
    "data_module = DATALOADER_DIRECTORY[dict_args['dataloader']](**dict_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Trainer: initialize training behaviour\n",
    "profiler = SimpleProfiler()\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "# logger = TensorBoardLogger(save_dir=dict_args['logdir'], version=now, name='lightning_logs', log_graph=True)\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project='egostanrepo_mo2cap2',  # Replace with your project name\n",
    "    # name='orgin_mo2cap2',  # Replace with your experiment name\n",
    "    save_dir=dict_args['logdir'],\n",
    "    version=now\n",
    ")\n",
    "# logger = None\n",
    "\n",
    "if dict_args['gpus'] > 1:\n",
    "\taccelerator = 'dp'\n",
    "elif dict_args['gpus'] == 1:\n",
    "\taccelerator = 'gpu'\n",
    "elif dict_args['gpus'] == 0:\n",
    "\taccelerator = 'cpu'\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "\tcallbacks=[early_stopping_callback, checkpoint_callback, lr_monitor],\n",
    "\tval_check_interval=dict_args['val_freq'],\n",
    "\tdeterministic=True,\n",
    "\tgpus=dict_args['gpus'],\n",
    "\tprofiler=profiler,\n",
    "\tlogger=logger,\n",
    "\tmax_epochs=dict_args[\"epoch\"],\n",
    "\tlog_every_n_steps=10,\n",
    "\tgradient_clip_val=dict_args['clip_grad_norm'],\n",
    "\tresume_from_checkpoint=dict_args['resume_from_checkpoint'],\n",
    "\taccelerator=accelerator\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\user\\anaconda3\\envs\\mm\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvhehduatks\u001b[0m (\u001b[33mcv04\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\temp_res\\wandb\\run-20240819_142347-0819142329</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cv04/egostanrepo_mo2cap2/runs/0819142329' target=\"_blank\">0819142329</a></strong> to <a href='https://wandb.ai/cv04/egostanrepo_mo2cap2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cv04/egostanrepo_mo2cap2' target=\"_blank\">https://wandb.ai/cv04/egostanrepo_mo2cap2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cv04/egostanrepo_mo2cap2/runs/0819142329' target=\"_blank\">https://wandb.ai/cv04/egostanrepo_mo2cap2/runs/0819142329</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type           | Params | In sizes         | Out sizes      \n",
      "----------------------------------------------------------------------------------------\n",
      "0 | heatmap         | HeatMap        | 61.5 M | [1, 3, 368, 368] | [1, 15, 47, 47]\n",
      "1 | encoder         | Encoder        | 40.0 M | [1, 15, 47, 47]  | [1, 20]        \n",
      "2 | pose_decoder    | PoseDecoder    | 3.2 K  | [1, 20]          | [1, 15, 3]     \n",
      "3 | heatmap_decoder | HeatmapDecoder | 40.0 M | [1, 20]          | [1, 15, 47, 47]\n",
      "----------------------------------------------------------------------------------------\n",
      "141 M     Trainable params\n",
      "0         Non-trainable params\n",
      "141 M     Total params\n",
      "566.168   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e84eff9b55248028a3a1ceb00aeff47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a687f1158948c2a76a494b01d9dd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfa7ac2dd364d2db7c0b7374469f960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mpjpe_full_body improved. New best score: 0.294\n",
      "Epoch 0, global step 65: val_mpjpe_full_body reached 0.29366 (best 0.29366), saving model to \"C:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\temp_res\\models\\state_dict\\0819142329\\epoch=0-step=65.ckpt\" as top 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316d91f8803145bfa4f44fa35d790629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 131: val_mpjpe_full_body reached 207.44667 (best 0.29366), saving model to \"C:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\temp_res\\models\\state_dict\\0819142329\\epoch=0-step=131.ckpt\" as top 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215f3014c48b4141920185669f057334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 197: val_mpjpe_full_body reached 243.10242 (best 0.29366), saving model to \"C:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\temp_res\\models\\state_dict\\0819142329\\epoch=0-step=197.ckpt\" as top 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a367887a99c4498d9d3548838eddab1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 263: val_mpjpe_full_body reached 115.01862 (best 0.29366), saving model to \"C:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\temp_res\\models\\state_dict\\0819142329\\epoch=0-step=263.ckpt\" as top 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a4e25e14a64170b18b15794e36215e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 329: val_mpjpe_full_body reached 103.39344 (best 0.29366), saving model to \"C:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\temp_res\\models\\state_dict\\0819142329\\epoch=0-step=329.ckpt\" as top 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc62a5fb54244bfaa627200b22a51fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_mpjpe_full_body did not improve in the last 5 records. Best score: 0.294. Signaling Trainer to stop.\n",
      "Epoch 0, global step 395: val_mpjpe_full_body reached 102.05797 (best 0.29366), saving model to \"C:\\Users\\user\\Documents\\GitHub\\Ego-STAN\\temp_res\\models\\state_dict\\0819142329\\epoch=0-step=395.ckpt\" as top 5\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  739.05         \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  677.56         \t|1              \t|  677.56         \t|  91.681         \t|\n",
      "run_training_batch                 \t|  0.62082        \t|396            \t|  245.85         \t|  33.265         \t|\n",
      "evaluation_step_and_end            \t|  0.31793        \t|380            \t|  120.81         \t|  16.347         \t|\n",
      "validation_step                    \t|  0.3178         \t|380            \t|  120.77         \t|  16.341         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.24275        \t|396            \t|  96.128         \t|  13.007         \t|\n",
      "training_step_and_backward         \t|  0.23542        \t|396            \t|  93.227         \t|  12.614         \t|\n",
      "model_forward                      \t|  0.21508        \t|396            \t|  85.17          \t|  11.524         \t|\n",
      "training_step                      \t|  0.21504        \t|396            \t|  85.154         \t|  11.522         \t|\n",
      "get_train_batch                    \t|  0.15238        \t|397            \t|  60.495         \t|  8.1855         \t|\n",
      "fetch_next_train_batch             \t|  0.15234        \t|397            \t|  60.48          \t|  8.1835         \t|\n",
      "on_validation_end                  \t|  4.4776         \t|7              \t|  31.343         \t|  4.241          \t|\n",
      "get_validate_batch                 \t|  0.072253       \t|384            \t|  27.745         \t|  3.7542         \t|\n",
      "fetch_next_validate_batch          \t|  0.072211       \t|384            \t|  27.729         \t|  3.752          \t|\n",
      "backward                           \t|  0.019631       \t|396            \t|  7.774          \t|  1.0519         \t|\n",
      "on_pretrain_routine_start          \t|  2.969          \t|1              \t|  2.969          \t|  0.40173        \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.474          \t|3              \t|  1.422          \t|  0.19241        \t|\n",
      "get_sanity_check_batch             \t|  0.474          \t|3              \t|  1.422          \t|  0.19241        \t|\n",
      "on_validation_batch_end            \t|  0.0023184      \t|380            \t|  0.881          \t|  0.11921        \t|\n",
      "on_train_batch_end                 \t|  0.0016591      \t|396            \t|  0.657          \t|  0.088898       \t|\n",
      "evaluation_batch_to_device         \t|  0.0011026      \t|380            \t|  0.419          \t|  0.056695       \t|\n",
      "training_batch_to_device           \t|  0.00066919     \t|396            \t|  0.265          \t|  0.035857       \t|\n",
      "zero_grad                          \t|  0.00063384     \t|396            \t|  0.251          \t|  0.033963       \t|\n",
      "on_validation_start                \t|  0.013571       \t|7              \t|  0.095          \t|  0.012854       \t|\n",
      "on_train_batch_start               \t|  0.00019192     \t|396            \t|  0.076          \t|  0.010284       \t|\n",
      "on_sanity_check_start              \t|  0.031          \t|1              \t|  0.031          \t|  0.0041946      \t|\n",
      "on_train_start                     \t|  0.031          \t|1              \t|  0.031          \t|  0.0041946      \t|\n",
      "on_batch_start                     \t|  4.0404e-05     \t|396            \t|  0.016          \t|  0.002165       \t|\n",
      "configure_callbacks                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "prepare_data                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_before_accelerator_backend_setup\t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "setup                              \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "configure_sharded_model            \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_configure_sharded_model         \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "configure_optimizers               \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_fit_start                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_pretrain_routine_end            \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_val_dataloader                  \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_model_eval           \t|  0.0            \t|7              \t|  0.0            \t|  0.0            \t|\n",
      "on_epoch_start                     \t|  0.0            \t|8              \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_epoch_start          \t|  0.0            \t|7              \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_batch_start          \t|  0.0            \t|380            \t|  0.0            \t|  0.0            \t|\n",
      "validation_step_end                \t|  0.0            \t|380            \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_epoch_end            \t|  0.0            \t|7              \t|  0.0            \t|  0.0            \t|\n",
      "on_epoch_end                       \t|  0.0            \t|8              \t|  0.0            \t|  0.0            \t|\n",
      "on_sanity_check_end                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_train_dataloader                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_train_epoch_start               \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "training_step_end                  \t|  0.0            \t|396            \t|  0.0            \t|  0.0            \t|\n",
      "on_before_zero_grad                \t|  0.0            \t|396            \t|  0.0            \t|  0.0            \t|\n",
      "on_before_backward                 \t|  0.0            \t|396            \t|  0.0            \t|  0.0            \t|\n",
      "on_after_backward                  \t|  0.0            \t|396            \t|  0.0            \t|  0.0            \t|\n",
      "on_before_optimizer_step           \t|  0.0            \t|396            \t|  0.0            \t|  0.0            \t|\n",
      "on_batch_end                       \t|  0.0            \t|396            \t|  0.0            \t|  0.0            \t|\n",
      "on_train_epoch_end                 \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_train_end                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_fit_end                         \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "teardown                           \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation skipped\n"
     ]
    }
   ],
   "source": [
    "# Trainer: train model\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "# Evaluate model on best ckpt (defined in 'ModelCheckpoint' callback)\n",
    "if dict_args['eval'] and dict_args['dataset_test']:\n",
    "\ttrainer.test(model, ckpt_path='best', datamodule=data_module)\n",
    "\ttest_mpjpe_dict = model.test_results\n",
    "\tmpjpe_csv_path = os.path.join(weight_save_dir, f'{now}_eval.csv')\n",
    "\t# Store mpjpe test results as a csv\n",
    "\tcreate_results_csv(test_mpjpe_dict, mpjpe_csv_path, dict_args['dataloader'], dict_args['csv_mode'])\n",
    "else:\n",
    "\tprint(\"Evaluation skipped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
